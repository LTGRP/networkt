The breakdown of the implementation section of this paper will break apart every package into a section. Subsequently every single module will be a subsection. At the top of the section will be a brief package definition (what the package does, how it does it) on a high level.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Database Structure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The database structure was designed to be as simple and extensible as possible. There are three tables, 'edge', 'node', and 'status'. As you may imagine, the 'edge' table stores all relationships between 'node' objects, the 'node' table stores all nodes, and the 'status' table stores all statuses.
\subsection{ORM \& Design Decisions}
The ORM of choice for this project was SqlAlchemy due to its' highly adaptable nature and clean access to an agnostic SQL backend (you are able to use Sqlite, Postgresql, Mysql... with SqlAlchemy). Unfortunately the nature of SqlAlchemy is that is not a document database, it is a relational database. Other databases such as MongoDB, and Neo4j support graph operations, at the cost of a less clean integration with the Python workflow. Furthermore, MongoDB has been shown to be unreliable, losing records, crashing, etc. For this reason, SQL Alchemy was chosen.
\subsection{The Declarative Base}
The Declarative Base is a special feature of SQLAlchemy. By extending the base class and providing some protected members with metadata, we are able to create a table of a given type in SQLAlchemy. In the example below, we have created a class Node that extends Base. For our metadata we have provided \verb|__tablename__| which indicates what the table name within our database will be. Additionally we have defined all of the fields and their types which will automatically be instantiated by SQLAlchemy when the engine is created. Additionally you'll see that we have a one:many relationship defined between a given Node and a set of Statuses. That is, a Node can have multiple Statuses (this represents all of the tweets made by the user).
\\
\\
\subsection{The Declarative Base: The Node Class}
The Node Class represents a node within the system. It contains all of the information that is available within the Twitter public API. The following class description shows which fields are available.
\begin{lstlisting}
  class Node(Base):
    __tablename__ = 'node'
    id = Column(Integer, primary_key=True)
    created_at = Column(Text)
    description = Column(Text)
    favorites_count = Column(Integer)
    followers_count = Column(Integer)
    friends_count = Column(Integer)
    id_str = Column(Text)
    lang = Column(Text)
    listed_count = Column(Integer)
    location = Column(Text)
    name = Column(Text)
    screen_name = Column(Text)
    statuses_count = Column(Integer)
    time_zone = Column(Text)
    utc_offset = Column(Integer)
    verified = Column(Boolean)

    # Filtering Levels
    filter_0 = Column(Boolean)
    filter_1 = Column(Boolean)
    filter_2 = Column(Boolean)
    # Relationship to Status Updates
    statuses = relationship("Status", order_by="Status.date",
                            backref="node", cascade="all, delete")
\end{lstlisting}

As alluded to earlier, relational databases do not support graphs or graph operations. In order to facilitate this, the Node class contains a set of definitions for the manipulation of a graph. One can add edges, detect inbound edges (reference nodes), and outbound edges (pointer nodes).

\begin{lstlisting}
    def add_edge(self, *nodes):
        for node in nodes:
            Edge(self, node)
        return self

    def add_edge_reference(self, *nodes):
        for node in nodes:
            Edge(node, self)
        return self

    def pointer_nodes(self):
        return [i.pointer_node for i in self.reference_edges]

    def reference_nodes(self):
        return [i.reference_node for i in self.pointer_edges]
\end{lstlisting}

\subsection{The Declarative Base: The Edge Class}
The Edge class is what makes all of this possible. The Edge class and corresponding Edge table glue everything together. The Edge table is very simple, it contains two fields, \verb|reference_id| and \verb|pointer_id|. Every single row in table represents a relationship between two Nodes. The Node with the \verb|reference_id| is pointing to the Node with the \verb|pointer_id|. This means that the \verb|pointer_id| Node has an outbound edge to the \verb|reference_id| and vice versa.

\begin{lstlisting}
class Edge(Base):
    __tablename__ = 'edge'

    reference_id = Column(Integer,
                          ForeignKey('node.id'),
                          primary_key=True)

    pointer_id = Column(Integer,
                        ForeignKey('node.id'),
                        primary_key=True)

    reference_node = relationship(Node,
                                  primaryjoin=reference_id == Node.id,
                                  backref='reference_edges')
    pointer_node = relationship(Node,
                                primaryjoin=pointer_id == Node.id,
                                backref='pointer_edges')

    def __init__(self, n1, n2):
        self.reference_node = n1
        self.pointer_node = n2
\end{lstlisting}


\subsection{The Declarative Base: The  Status Class}
The Status class is responsible for maintaining all of the statuses of every user within the network. This class is important because it contains all of the data that is fed into our clustering sequence for identifying the diffusion of information. The Status class has a one to many relationship with the Node class, that is- a node object has many status objects.
\begin{lstlisting}
class Status(Base):
    __tablename__ = 'status'
    id = Column(Integer, primary_key=True)
    # Parent
    node_id = Column(Integer, ForeignKey('node.id'))
    # Fields
    coordinate_longitude = Column(Text)
    coordinate_latitude = Column(Text)
    created_at = Column(Text)
    date = Column(DateTime)
    favorite_count = Column(Integer)
    id_str = Column(Text)
    in_reply_to_screen_name = Column(Text)
    in_reply_to_status_id_str = Column(Text)
    in_reply_to_user_id_str = Column(Text)
    lang = Column(Text)
    possibly_sensitive = Column(Boolean)
    quoted_status_id_str = Column(Text)
    retweet_count = Column(Integer)
    retweeted = Column(Boolean)
    source = Column(Text)
    text = Column(Text)
    truncated = Column(Boolean)
\end{lstlisting}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Graph}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The Graph package contains all of the important definitions for the database structure, access, and extraction of data from Twitter.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Scrapet}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Scrapet is the tool that is responsible for pulling the data from the Twitter API and making the appropriate graphs. Scrapet is the core behind all of the tools in the project. Every single project will end up using a Scrapet dump of data for rendering, machine learning, or any other processes necessary for analysis. This tool is composed of a number of components which will be briefly be introduced below. Following the introduction and description of components, the high level architecture will be explained.
\subsection{Scrapet.ini}
The Ini file is important for saving many configuration details.
\subsection{Logger}
The logger is the most important component of the Scrapet system. The logger is an abstract entity that is either fulfilled as a console logger, or as a GUI logger depending on the flavor and execution method of the Scrapet build. The logger is responsible for reporting on the overall progress and the activity of the system.
\subsection{Runner}
The runner is the main entry point of the system. Whether running from the GUI mode, or from the command line mode, Scrapet always begins here. This is where all of the scraping algorithms and functions are organized.
\subsection{Main}
Main is aptly named as the Main entry point into the program. This is where the GUI version of Scrapet begins. Just like the command line program though, the true entry point of execution is in Runner. During execution of the scraping process, scrapet launches 'Runner' as a thread.
\subsection{Settings Panel}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Networkt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Networkt description.
\subsection{Main}
Main Description
\subsection{Network}
Network Description
\subsection{Node}
Node Description
\subsection{Status}
Status Object Description
\subsection{Camera}
Camera Description
\subsection{Range Slider}
Written by \verb|https://groups.google.com/forum/#!topic/kivy-users/oMFx0YKW5oA| 'Werton'
\subsection{Preview Range Slider}
Preview Range Slider
\subsection{Preview slider}
Preview Slider Description

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Cluster}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The best way to understand the cluster package is to go through it line by line.

\begin{lstlisting}
import os
import string
import collections

from configparser import ConfigParser
from nltk import word_tokenize
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from graph.initialize import Base, Node


def process_text(text, stem=True):
    """ Tokenize text and stem words removing punctuation """
    transtable = {ord(s): None for s in string.punctuation}
    transtable[ord('/')] = u''
    text = text.translate(transtable)
    tokens = word_tokenize(text)
    
    if stem:
        stemmer = PorterStemmer()
        tokens = [stemmer.stem(t) for t in tokens]
        
    return tokens


def cluster_texts(texts, clusters=3):
    """ Transform texts to Tf-Idf coordinates and cluster texts using K-Means """
    vectorizer = TfidfVectorizer(tokenizer=process_text,
                                 stop_words=stopwords.words('english'),
                                 max_df=0.5,
                                 min_df=0.0,
                                 lowercase=True)
 
    tfidf_model = vectorizer.fit_transform(texts)
    km_model = KMeans(n_clusters=clusters)
    km_model.fit(tfidf_model)
 
    clustering = collections.defaultdict(list)
 
    for idx, label in enumerate(km_model.labels_):
        clustering[label].append(idx)
 
    return clustering


def create_session():
    config = ConfigParser()
    config.read(os.path.expanduser('~/.config/networkt/cluster.ini'))
    DATABASE_NAME = 'sqlite:///{}/data_store.db'.format(config.get('persistence-configuration', 'database_path'))
    engine = create_engine(DATABASE_NAME)
    Base.metadata.bind = engine
    DBSession = sessionmaker(bind=engine)
    session = DBSession()
    return session


if __name__ == "__main__":
    session = create_session()
    transnational_users = session.query(Node).filter_by(filter_1=True).all()
    for user in transnational_users[0:1]:
        print('User ', user.screen_name)
        statuses = []
        statuses = statuses + user.statuses
        for node in user.reference_nodes():
            statuses = statuses + node.statuses
        for node in user.pointer_nodes():
            statuses = statuses + node.statuses
        
        statuses.sort()
        documents = [i.text for i in statuses]
        print('Documents Gathered')
        cluster_count = 500
        clusters = cluster_texts(documents, cluster_count)
        clusteri = dict(clusters)
        for key in clusteri:
            print('idx {} cnt {}'.format(key, len(clusteri[key])))
        
        # Assign Cluster and Corresponding Values
        for key in clusteri:
            for idx in clusteri[key]:
                statuses[idx].cluster = key
        
        # Iterate through Transnational Tweets
        for index, status in enumerate(statuses):
            # Transnational Tweet - Check for Diffusion
            if (status.node == user):
                statuses_before = statuses[index - 10:index]
                statuses_after = statuses[index:index + 10]
                
                # Filter Before for Friend Relationships
                statuses_before_filtered = []
                for statusi in statuses_before:
                    if statusi.node in user.reference_nodes():
                        statuses_before_filtered.append(statusi)
                statuses_before = statuses_before_filtered
                
                # Filter After for Follower Relationships
                statuses_after_filtered = []
                for statusi in statuses_after:
                    if statusi.node in user.pointer_nodes():
                        statuses_after_filtered.append(statusi)
                statuses_after = statuses_after_filtered
                
                statuses_before = [i for i in statuses_before if i.cluster == status.cluster]
                statuses_after = [i for i in statuses_after if i.cluster == status.cluster]
                
                # If Statuses of same cluster exist before and after print them
                if (len(statuses_before) > 0 and len(statuses_after) > 0):
                    print('=' * 80)
                    
                    print('friend statuses before tweet')
                    print('-' * 80)
                    for text in [i.text for i in statuses_before]:
                        print(text)
                    
                    print('\ntransnational status')
                    print('-' * 80)
                    print(status.text)
                    
                    print('\nfollower statuses after tweet')
                    print('-' * 80)
                    for text in [i.text for i in statuses_after]:
                        print(text)
                    
                    print('\n')
\end{lstlisting}
