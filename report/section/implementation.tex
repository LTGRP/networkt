The goal of the imlementation section is to concretely describe how
the software was written, how it all fits together, and what are the
actual operations it performs. The implementation section is a
definition of how the Method was carried out on a programmatic level.

\section{The Database Structure}
The database structure was designed to mimic the nature of the twitter
network graph as closely as possible. For this reason, the datastore
of choice for this project was Neo4j. Neo4j was chosen because of its
powerful ability to model graphs and networks. Neo4j ships with native
implementations to connect nodes together, as well as cypher, a
powerful query language. As an example, cypher is used to select the
tweets of all the individuals in a transnational network, using just
one command.

The database contains several types of objects to represent different
parts of the twitter network. The objects will explained below.

\section{Graph}
The Graph package contains all of the important definitions for the
database structure, access, and extraction of data from Twitter. It is
composed of three important modules:

\begin{enumerate}
\item Data Model
\item Filter Node
\item Network Scrape
\end{enumerate}

\subsection{Data Model}
The data model is where the representations for all of the objects on
Twitter are stored. The representations are designed to capture all of
the useful information available from the Twitter API in an indexable
and computable way.

\subsubsection{The Node Class}
The Node Class represents a node within the system. A node, within
this context, refers to a user on Twitter. The Node contains all of
the information that is available within the Twitter public API. The
following class description shows which fields are available.

\begin{lstlisting}
class Node(StructuredNode):
    name = StringProperty()
    screen_name = StringProperty(unique_index=True)
    
    created_at = StringProperty()
    description = StringProperty()
    favorites_count = IntegerProperty()
    followers_count = IntegerProperty()
    friends_count = IntegerProperty()
    id_str = StringProperty()
    lang = StringProperty()
    listed_count = IntegerProperty()
    location = StringProperty()
    statuses_count = IntegerProperty()
    time_zone = StringProperty()
    utc_offset = IntegerProperty()
    verified = BooleanProperty()
    
    # Relationship definitions
    friends = RelationshipTo('Node', 'FRIEND')
    followers = RelationshipTo('Node', 'FOLLOWER')
    statuses = RelationshipTo('Status', 'STATUS')
    tags = RelationshipTo('Tag', 'TAG')
\end{lstlisting}

This object is used to model a given Twitter user and can be used to
persist all of the important information about them. By breaking apart
the user model into fields of interest, we are able to write queries
that target specific properties of users- for example- we can write a
query to return all users with a location of X.

\subsubsection{The  Status Class}
The Status class is responsible for maintaining all of the statuses of
every user within the network. That is, the status class is a
representation of a Tweet. This class is important because it contains
all of the data that is fed into our clustering sequence for
identifying the diffusion of information. The Status class has a one
to many relationship with the Node class- a node object has many
status objects.

\begin{lstlisting}
class Status(StructuredNode):
  id_str = StringProperty(unique_index=True)

  coordinate_longitude = StringProperty()
  coordinate_latitude = StringProperty()
  created_at = StringProperty()
  date = DateTimeProperty()
  favorite_count = IntegerProperty()
  in_reply_to_screen_name = StringProperty()
  in_reply_to_status_id_str = StringProperty()
  in_reply_to_user_id_str = StringProperty()
  lang = StringProperty()
  possibly_sensitive = BooleanProperty()
  quoted_status_id_str = StringProperty()
  retweet_count = IntegerProperty()
  retweeted = BooleanProperty()
  source = StringProperty()
  text = StringProperty()
  truncated = BooleanProperty()
\end{lstlisting}

As with the Node class, the Status class represents and classifies all
information available about a given Tweet published on Twitter.

\subsection{Filter Node}
The filter node module is responsible for all operations relating to
classifying different nodes during the network scraping
process. Within filter node there are a set of functions called
``filter x'' that accept a Node object as input, and return a true or
false value as to whether a given Node qualifies for a particular
attribute.

To provide a concrete example of Node filtering, consider
identification of Transnational Entrepreneurs. Due to the Twitter
API's rate limits, different filtering strategies are used to
determine the liklihood that a given user is a Transnational
Entrpreneur. This helps improve the performance of collecting networks
of interest on Twitter. During the initial collection of followers of
a startup hub, the filter\_1 function, will determine whether a sample
network of a user qualifies them as being a Transnational candidate.

\subsection{Network Scrape}
The network scrape module contains a set of functions for extracting a
network of a Twitter user in a reliable way. Within network scrape,
there are functions available to:

\begin{enumerate}
\item Get a single User and persist them
\item Get a User's ego-centric follower network and persist them
\item Get a User's ego-centric friend network and persist them
\item Get a User's Status' and persist them
\end{enumerate}

Together, composting these functions allows for a snapshot of a given
individual's network. By abstracting away the functions of the Twitter
API in the Network Scrape module, extracting a user's Twitter network
is significantly eased.

There are several constraints that the Network Scrape module
considers. One of the primary constraints is, that there are different
rate limits for different operations within the Twitter API, therefore
to respect the rate limits and avoid being rate limited, it is
necessary for the program to adjust the amount of time it waits
between each operation. Another constraint which provides significant
problems is that the Twitter API may sometimes confirm the existence
of a user by returning them as a friend or follower of a given user,
but simultaneously prohibit the collection of data via the API for
that user. If this behavior is not accounted for, the Network
representation within Neo4j may contain empty Nodes, or Nodes without
statuses. These problems and others are all abstracted by Network
Scrape, so that the Scrapet package runner module can easily extract
and persist a network snapshot from Twitter to Neo4j.

\section{Cluster}
The best way to understand the cluster package is to go through it
line by line.

\begin{lstlisting}
import os
...
\end{lstlisting}
