The breakdown of the implementation section of this paper will break apart every package into a section. Subsequently every single module will be a subsection. At the top of the section will be a brief package definition (what the package does, how it does it) on a high level.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Database Structure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The database structure was designed to be as simple and extensible as possible.

\subsection{ORM \& Design Decisions}
The ORM of choice for this project was Neo4j.

\subsection{The Declarative Base: The Node Class}
The Node Class represents a node within the system. It contains all of the information that is available within the Twitter public API. The following class description shows which fields are available.

\begin{lstlisting}
  class Node(Base):
    __tablename__ = 'node'
    id = Column(Integer, primary_key=True)
    created_at = Column(Text)
    description = Column(Text)
    favorites_count = Column(Integer)
    followers_count = Column(Integer)
    friends_count = Column(Integer)
    id_str = Column(Text)
    lang = Column(Text)
    listed_count = Column(Integer)
    location = Column(Text)
    name = Column(Text)
    screen_name = Column(Text)
    statuses_count = Column(Integer)
    time_zone = Column(Text)
    utc_offset = Column(Integer)
    verified = Column(Boolean)

    # Filtering Levels
    filter_0 = Column(Boolean)
    filter_1 = Column(Boolean)
    filter_2 = Column(Boolean)
    # Relationship to Status Updates
    statuses = relationship("Status", order_by="Status.date",
                            backref="node", cascade="all, delete")
\end{lstlisting}

\subsection{The Declarative Base: The  Status Class}
The Status class is responsible for maintaining all of the statuses of every user within the network. This class is important because it contains all of the data that is fed into our clustering sequence for identifying the diffusion of information. The Status class has a one to many relationship with the Node class, that is- a node object has many status objects.

\begin{lstlisting}
class Status(Base):
    __tablename__ = 'status'
    id = Column(Integer, primary_key=True)
    # Parent
    node_id = Column(Integer, ForeignKey('node.id'))
    # Fields
    coordinate_longitude = Column(Text)
    coordinate_latitude = Column(Text)
    created_at = Column(Text)
    date = Column(DateTime)
    favorite_count = Column(Integer)
    id_str = Column(Text)
    in_reply_to_screen_name = Column(Text)
    in_reply_to_status_id_str = Column(Text)
    in_reply_to_user_id_str = Column(Text)
    lang = Column(Text)
    possibly_sensitive = Column(Boolean)
    quoted_status_id_str = Column(Text)
    retweet_count = Column(Integer)
    retweeted = Column(Boolean)
    source = Column(Text)
    text = Column(Text)
    truncated = Column(Boolean)
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Graph}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The Graph package contains all of the important definitions for the database structure, access, and extraction of data from Twitter.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Scrapet}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Scrapet is the tool that is responsible for pulling the data from the Twitter API and making the appropriate graphs. Scrapet is the core behind all of the tools in the project. Every single project will end up using a Scrapet dump of data for rendering, machine learning, or any other processes necessary for analysis. This tool is composed of a number of components which will be briefly be introduced below. Following the introduction and description of components, the high level architecture will be explained.

\subsection{Scrapet.ini}
The Ini file is important for saving many configuration details.

\subsection{Logger}
The logger is the most important component of the Scrapet system. The logger is an abstract entity that is either fulfilled as a console logger, or as a GUI logger depending on the flavor and execution method of the Scrapet build. The logger is responsible for reporting on the overall progress and the activity of the system.

\subsection{Runner}
The runner is the main entry point of the system. Whether running from the GUI mode, or from the command line mode, Scrapet always begins here. This is where all of the scraping algorithms and functions are organized.

\subsection{Main}
Main is aptly named as the main entry point into the program. This is where the GUI version of Scrapet begins. Just like the command line program though, the true entry point of execution is in Runner. During execution of the scraping process, scrapet launches 'Runner' as a thread.

\subsection{Settings Panel}
The settings panel provides an abstract way to edit the ini file which controls the behavior of the runner. In this way it is possible to use the GUI to set the parameters that the command line program will operate with, as they launch the same subprocess - directly or otherwise.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Networkt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Networkt is a program for the visualization of the activity of a network throughout time. Designed as a tool for qualitative analysts to find relevant information and look for patterns that they can manually investigate. The tool is a 4D visualization tool akin to something like Gephi in appearance, but functional in the respect that it can playback the recorded activity of nodes on a network.

\subsection{Main}
As with other packages, Main is the is the main entry point into the program. This is where the GUI starts. All graph data is initialized in Main before the program returns the GUI.

\subsection{Network}
Network is the name of the high level Network view. What Network does is, given a set of nodes, it will draw them to the screen. It'll draw them using the Fruchterman-Reingold algorithm. Then, the program when in 'play' mode will signal the Network widget object that time has passed. The Network object will note how much time has passed and how many events from which nodes have been fired off. After collecting the set of fired nodes, it'll initiate the node firing process and actually send the 'messages' between the nodes so that the user can observe them.

\subsection{Node}
Node is the module responsible for all representation and logic of a node. The node module contains vertex instructions for drawing, a list of all references to all the status objects of a particular node, and other rendering information. For example, any node property might be used to affect the drawing instructions. When a node is clicked on in the Network widget, all of its' information is displayed in the right hand sidebar.

\subsection{Status}
The Status object represents a tweet. It, like the Node object contains all the information and representation logic necessary for usage by Networkt. It has a date, message body, language, etc, every single field available from twitter, any one of these parameters may be used to influence the behavior of the tweets as they travel across the network e.g. they move quicker between the nodes, they are colored red, etc.

\subsection{Camera}
The Camera object and module represents the camera control by the end user. If the user is to move around the objects on the map, we can't actually update their relative positions as defined by the layout algorithm. Instead what we do is we mark an offset on them, if the user pans the map down, then we offset all of the objects up. If the user zooms in, then we multiply the coordinates of the objects so that they occupy a bigger space. All of these actions result in a 'movement' of a camera without actually updating the object properties. The camera offsets are calculated and incorporated during render time.

\subsection{Range Slider}
Written by \verb|https://groups.google.com/forum/#!topic/kivy-users/oMFx0YKW5oA| 'Werton'

\subsection{Preview Range Slider}
Preview Range Slider

\subsection{Preview slider}
Preview Slider Description

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Cluster}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The best way to understand the cluster package is to go through it line by line.

\begin{lstlisting}
import os
import string
import collections

from configparser import ConfigParser
from nltk import word_tokenize
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from graph.initialize import Base, Node


def process_text(text, stem=True):
    """ Tokenize text and stem words removing punctuation """
    transtable = {ord(s): None for s in string.punctuation}
    transtable[ord('/')] = u''
    text = text.translate(transtable)
    tokens = word_tokenize(text)
    
    if stem:
        stemmer = PorterStemmer()
        tokens = [stemmer.stem(t) for t in tokens]
        
    return tokens


def cluster_texts(texts, clusters=3):
    """ Transform texts to Tf-Idf coordinates and cluster texts using K-Means """
    vectorizer = TfidfVectorizer(tokenizer=process_text,
                                 stop_words=stopwords.words('english'),
                                 max_df=0.5,
                                 min_df=0.0,
                                 lowercase=True)
 
    tfidf_model = vectorizer.fit_transform(texts)
    km_model = KMeans(n_clusters=clusters)
    km_model.fit(tfidf_model)
 
    clustering = collections.defaultdict(list)
 
    for idx, label in enumerate(km_model.labels_):
        clustering[label].append(idx)
 
    return clustering


def create_session():
    config = ConfigParser()
    config.read(os.path.expanduser('~/.config/networkt/cluster.ini'))
    DATABASE_NAME = 'sqlite:///{}/data_store.db'.format(config.get('persistence-configuration', 'database_path'))
    engine = create_engine(DATABASE_NAME)
    Base.metadata.bind = engine
    DBSession = sessionmaker(bind=engine)
    session = DBSession()
    return session


if __name__ == "__main__":
    session = create_session()
    transnational_users = session.query(Node).filter_by(filter_1=True).all()
    for user in transnational_users[0:1]:
        print('User ', user.screen_name)
        statuses = []
        statuses = statuses + user.statuses
        for node in user.reference_nodes():
            statuses = statuses + node.statuses
        for node in user.pointer_nodes():
            statuses = statuses + node.statuses
        
        statuses.sort()
        documents = [i.text for i in statuses]
        print('Documents Gathered')
        cluster_count = 500
        clusters = cluster_texts(documents, cluster_count)
        clusteri = dict(clusters)
        for key in clusteri:
            print('idx {} cnt {}'.format(key, len(clusteri[key])))
        
        # Assign Cluster and Corresponding Values
        for key in clusteri:
            for idx in clusteri[key]:
                statuses[idx].cluster = key
        
        # Iterate through Transnational Tweets
        for index, status in enumerate(statuses):
            # Transnational Tweet - Check for Diffusion
            if (status.node == user):
                statuses_before = statuses[index - 10:index]
                statuses_after = statuses[index:index + 10]
                
                # Filter Before for Friend Relationships
                statuses_before_filtered = []
                for statusi in statuses_before:
                    if statusi.node in user.reference_nodes():
                        statuses_before_filtered.append(statusi)
                statuses_before = statuses_before_filtered
                
                # Filter After for Follower Relationships
                statuses_after_filtered = []
                for statusi in statuses_after:
                    if statusi.node in user.pointer_nodes():
                        statuses_after_filtered.append(statusi)
                statuses_after = statuses_after_filtered
                
                statuses_before = [i for i in statuses_before if i.cluster == status.cluster]
                statuses_after = [i for i in statuses_after if i.cluster == status.cluster]
                
                # If Statuses of same cluster exist before and after print them
                if (len(statuses_before) > 0 and len(statuses_after) > 0):
                    print('=' * 80)
                    
                    print('friend statuses before tweet')
                    print('-' * 80)
                    for text in [i.text for i in statuses_before]:
                        print(text)
                    
                    print('\ntransnational status')
                    print('-' * 80)
                    print(status.text)
                    
                    print('\nfollower statuses after tweet')
                    print('-' * 80)
                    for text in [i.text for i in statuses_after]:
                        print(text)
                    
                    print('\n')
\end{lstlisting}
